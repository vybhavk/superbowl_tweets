<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<pre><code>import pandas as pd
import sqlite3
import re
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage.filters import gaussian_filter
from scipy.signal import argrelextrema</code></pre>
<p>I have downloaded tweets using the Twitter Streaming API, and stored them tweets in a database. I used a filter so that I only capture tweets containing the word &quot;superbowl&quot;. Fortunately, pandas makes it incredibly easy to load the data and start playing with it using one simple query. I add one new column named 'hour_offset' which is simply the number of hours which have elapsed since midnight in New York. This is done to make histogramming easier. I also restrict the database to tweets that occured during the game itself. After doing this, I am left with about 1.5 million tweets.</p>
<pre><code>con = sqlite3.connect(&quot;tweets.db&quot;)
df = pd.read_sql(&quot;SELECT * from tweets&quot;, con, parse_dates=[&#39;created_at&#39;])
sunday_12_NYC = pd.to_datetime(&#39;2015-02-01 05:00:00&#39;,format=&quot;%Y-%m-%d %H:%M:%S&quot;)
df[&#39;hour_offset&#39;] = (df.created_at - sunday_12_NYC)/np.timedelta64(1,&#39;h&#39;)
df = df.loc[(df.hour_offset&gt;18.5)&amp;(df.hour_offset&lt;22.)]
len(df)




1498142</code></pre>
<p>Now, I plot histograms of the occurence of various words in tweets by time. We can easily pick out the occurance of each of the 7 touchdowns by eye, as well as the spikes caused by commercials. I have chosen to show tweets containing &quot;budweiser&quot;, &quot;snickers&quot;, and &quot;fiat&quot; as examples. We can also see the gap corresponding to the half-time show. This highlights the importance of ads in the superbowl. It indicates that by some measures, commercials can capture more attention of viewers than some touchdowns. The budweiser commercial seems to have been particularly engaging for people.</p>
<pre><code>def word_in_text(word,text):
        word = word.lower()
        text = text.lower()
        match = re.search(word,text)
        if match:
            return True
        return False
        
plt.figure(figsize=(8, 8))
plt.hist(df[df.content.apply(lambda x: word_in_text(&#39;touchdown&#39;,x))].hour_offset.values,bins=100,alpha=.25,label=&#39;touchdown&#39;)
plt.hist(df[df.content.apply(lambda x: word_in_text(&#39;budweiser&#39;,x))].hour_offset.values,bins=100,alpha=.25,label=&#39;budweiser&#39;)
plt.hist(df[df.content.apply(lambda x: word_in_text(&#39;snickers&#39;,x))].hour_offset.values,bins=100,alpha=.25,label=&#39;snickers&#39;)
plt.hist(df[df.content.apply(lambda x: word_in_text(&#39;fiat&#39;,x))].hour_offset.values,bins=100,alpha=.25,label=&#39;fiat&#39;)
plt.xlabel(&quot;hour&quot;)
plt.ylabel(&quot;counts&quot;)
legend(loc=&#39;best&#39;)
plt.savefig(&quot;hist.png&quot;)
plt.show()</code></pre>
<div class="figure">
<img src="superbowl_tweets_files/superbowl_tweets_4_0.png" alt="png" />
<p class="caption">png</p>
</div>
<p>One can think about how peoples priorities can vary over the course of the game. In particular, I want to compare people's interest in &quot;buying things&quot; vs. their interest in the game. I plot the counts in each minute bin for tweets containing the word &quot;buy&quot; vs counts for the word &quot;game&quot;. If they maintened a constant level of interest in each, you would expect to see one cluster only. Instead, you also see two distinct branches toward both the &quot;buy&quot; axis and the &quot;game&quot; axis. This shows that the context of what is happening can shift people's priorities to either buying the things, or paying attention to the game itself. This is expected, as people's attention is forced to switch between game play and commercial breaks, but a closer analysis may reveal other interesting influential factors, such as the score, minutes remaining in quarter, which down is being played, etc. I leave these questions for a future analysis.</p>
<pre><code>df[&#39;one_minute&#39;] = np.floor(df.hour_offset*60.)
game_rate = df[df.content.apply(lambda x: word_in_text(&#39;game&#39;,x))].groupby(&#39;one_minute&#39;).size()
buy_rate = df[df.content.apply(lambda x: word_in_text(&#39;buy&#39;,x))].groupby(&#39;one_minute&#39;).size()
plt.figure(figsize=(8, 8))
plt.scatter(game_rate,buy_rate)
plt.xlabel(&quot;tweets containing &#39;game&#39;&quot;)
plt.ylabel(&quot;tweets containing &#39;buy&#39;&quot;)
plt.savefig(&quot;scatter.png&quot;)
plt.show()</code></pre>
<div class="figure">
<img src="superbowl_tweets_files/superbowl_tweets_6_0.png" alt="png" />
<p class="caption">png</p>
</div>
<p>Just for fun, let's see if we can infer the number of touchdowns scored by each team, just based on twitter data. We select out tweets by people who identify themselves as living in either Boston or Seattle and count the number of times they tweet the word &quot;touchdown&quot; each minute. In each minute bin, we take the count difference for each group and set a floor on the result at 0. This accounts for the fact that some people also tweet &quot;touchdown&quot; when the opposing team scores, and we don't want to be confused by this. We then use a gaussian filter to smooth these curves, and count the number of local maxima above a given threshold. Lo and behold, we get the correct number of touchdowns for each team.</p>
<pre><code>touchdown_tweets = df[df.content.apply(lambda x: (word_in_text(&#39;touchdown&#39;,x)) )]
touchdown_boston = touchdown_tweets[touchdown_tweets.location.apply(lambda x: word_in_text(&#39;boston&#39;, x))]
touchdown_seattle = touchdown_tweets[touchdown_tweets.location.apply(lambda x: word_in_text(&#39;seattle&#39;, x))]
boston_touchdown_count = np.zeros(300)
seattle_touchdown_count = np.zeros(300)
for minute_count in touchdown_boston.one_minute:
    boston_touchdown_count[minute_count - 1110] +=1
for minute_count in touchdown_seattle.one_minute:
    seattle_touchdown_count[minute_count - 1110] +=1

s_td_smooth = gaussian_filter((seattle_touchdown_count - boston_touchdown_count).clip(min=0),2)
b_td_smooth = gaussian_filter((boston_touchdown_count - seattle_touchdown_count).clip(min=0),2)

def find_peaks_above_thresh(array,thresh):
    maxes = argrelextrema(array,np.greater)[0]
    return maxes[np.where(array[maxes]&gt;thresh)[0]]

seattle_peaks = find_peaks_above_thresh(s_td_smooth,2.)
boston_peaks = find_peaks_above_thresh(b_td_smooth,2.)
print &quot;seattle scored &quot;,len(seattle_peaks),&quot;touchdowns&quot;
print &quot;boston scored &quot;,len(boston_peaks),&quot;touchdowns&quot;

plt.figure(figsize=(8, 8))
plt.plot(s_td_smooth, label = &#39;Seattle&#39;,color=&quot;blue&quot;)
plt.plot(b_td_smooth, label = &#39;Boston&#39;,color = &quot;green&quot;)
for i in seattle_peaks:
    plt.plot((i, i), (0, 2), color=&#39;blue&#39;,linewidth=3.0)
for i in boston_peaks:
    plt.plot((i, i), (0, 2), color=&#39;green&#39;,linewidth=3.0)
plt.xlim(25,225)
plt.xlabel(&quot;minutes after kickoff&quot;)
legend(loc=&#39;best&#39;)
plt.savefig(&quot;touchdowns.png&quot;)
plt.show()

seattle scored  3 touchdowns
boston scored  4 touchdowns</code></pre>
<div class="figure">
<img src="superbowl_tweets_files/superbowl_tweets_8_1.png" alt="png" />
<p class="caption">png</p>
</div>
</body>
</html>
